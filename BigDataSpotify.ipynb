{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# LABORATORIO SPOTIFY\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "fWTLsDIeVuQd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings #esto elimino los warnings de colab\n",
        "\n",
        "warnings.filterwarnings('ignore', category=UserWarning)\n",
        "warnings.filterwarnings('ignore', category=DeprecationWarning)"
      ],
      "metadata": {
        "id": "O76-KZbnCKFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extraemos el archivo csv y lo pasamos a  formato pandas. Luego dividimos, en la variable etiqueta extraemos la columna target.En la variable caracteristica extraemos todas las columnas exceptuando \"Target , Song_Name, Artist\".Despues divimos los datos en un 80% para entrenamiento y un 20& para testeo."
      ],
      "metadata": {
        "id": "lSeRpWwcPvZh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QoD69yGswe9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "hola= pd.read_csv('/content/Canciones_Spotify.csv')\n",
        "\n",
        "etiqueta= hola['target']\n",
        "caracteristicas= hola\n",
        "\n",
        "etiqueta"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columnas_de_caracteristicas = [\"acousticness\", \"danceability\", \"duration_ms\", \"energy\", \"instrumentalness\", \"key\", \"liveness\", \"loudness\", \"mode\", \"speechiness\", \"tempo\", \"time_signature\", \"valence\"]\n",
        "\n",
        "# Crear un nuevo DataFrame con las columnas de características\n",
        "caracteristicas = hola[columnas_de_caracteristicas]\n",
        "\n",
        "caracteristicas"
      ],
      "metadata": {
        "id": "dVhOoFSYztGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(caracteristicas, etiqueta, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "bL6pH730z0DB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KNN (K-Nearest Neighbors)"
      ],
      "metadata": {
        "id": "_GB638ZARDFP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#KNN\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "# Entrenar el modelo\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "# Evaluar el rendimiento del modelo\n",
        "print(\"Precisión:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "xBFDysLp0DTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVM (Support Vector Machines)"
      ],
      "metadata": {
        "id": "BTXquNXsRRO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#SVC\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "svm = SVC(kernel='linear', C=1.0, random_state=42)\n",
        "\n",
        "# Entrenar el modelo\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "y_pred1 = svm.predict(X_test)\n",
        "\n",
        "# Evaluar el rendimiento del modelo\n",
        "print(\"Precisión:\", accuracy_score(y_test, y_pred1))\n",
        "print(classification_report(y_test, y_pred1))\n",
        "\n",
        "scores = cross_val_score(svm, X_train, y_train, cv=5, scoring='accuracy')\n",
        "\n",
        "# Imprimir los resultados de cada pliegue y la precisión media\n",
        "for i, score in enumerate(scores):\n",
        "    print(f\"Precisión en pliegue {i + 1}: {score}\")\n",
        "\n",
        "precisión_media = scores.mean()\n",
        "print(f\"Precisión media en Validación Cruzada k-fold (k=5): {precisión_media}\")"
      ],
      "metadata": {
        "id": "kEqUaX-g0gCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Árbol de decisión"
      ],
      "metadata": {
        "id": "8HtQzvvpRXyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#arbolito de decision\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Crear una instancia del modelo de Árbol de Decisión (puedes ajustar hiperparámetros)\n",
        "arbol_decision = DecisionTreeClassifier(max_depth=None, criterion=\"gini\")\n",
        "\n",
        "# Entrenar el modelo\n",
        "arbol_decision.fit(X_train, y_train)\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "y_pred2 = arbol_decision.predict(X_test)\n",
        "\n",
        "# Evaluar el rendimiento del modelo\n",
        "print(\"Precisión:\", accuracy_score(y_test, y_pred2))\n",
        "print(classification_report(y_test, y_pred2))\n",
        "\n",
        "scores = cross_val_score(arbol_decision, X_train, y_train, cv=5, scoring='accuracy')\n",
        "\n",
        "# Imprimir los resultados de cada pliegue y la precisión media\n",
        "for i, score in enumerate(scores):\n",
        "    print(f\"Precisión en pliegue {i + 1}: {score}\")\n",
        "\n",
        "precisión_media = scores.mean()\n",
        "print(f\"Precisión media en Validación Cruzada k-fold (k=5): {precisión_media}\")"
      ],
      "metadata": {
        "id": "zL8Nn2154K66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bayes (Naive Bayes)\n",
        "## Sección nueva"
      ],
      "metadata": {
        "id": "ib_T9_8SRa7r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#bayes\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Crear una instancia del modelo Naive Bayes (GaussianNB)\n",
        "naive_bayes = GaussianNB()\n",
        "\n",
        "# Entrenar el modelo\n",
        "naive_bayes.fit(X_train, y_train)\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "y_pred3 = naive_bayes.predict(X_test)\n",
        "\n",
        "# Evaluar el rendimiento del modelo\n",
        "print(\"Precisión:\", accuracy_score(y_test, y_pred3))\n",
        "print(classification_report(y_test, y_pred3))\n",
        "\n",
        "scores = cross_val_score(naive_bayes, X_train, y_train, cv=5, scoring='accuracy')\n",
        "\n",
        "# Imprimir los resultados de cada pliegue y la precisión media\n",
        "for i, score in enumerate(scores):\n",
        "    print(f\"Precisión en pliegue {i + 1}: {score}\")\n",
        "\n",
        "precisión_media = scores.mean()\n",
        "print(f\"Precisión media en Validación Cruzada k-fold (k=5): {precisión_media}\")"
      ],
      "metadata": {
        "id": "834ew76M4pPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Otro modelo"
      ],
      "metadata": {
        "id": "v54zIT6ARgCZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random forest"
      ],
      "metadata": {
        "id": "ggVeroQsRiN4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#arbolito random\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Entrenar el modelo\n",
        "random_forest.fit(X_train, y_train)\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "y_pred4 = random_forest.predict(X_test)\n",
        "\n",
        "# Evaluar el rendimiento del modelo\n",
        "print(\"Precisión:\", accuracy_score(y_test, y_pred4))\n",
        "print(classification_report(y_test, y_pred4))"
      ],
      "metadata": {
        "id": "7hkLvLii5M5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Redes neuronales"
      ],
      "metadata": {
        "id": "k4jJwsf2R4Rj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#redes neuronales con k-fold\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Crear una red neuronal con TensorFlow y Keras\n",
        "def build_model():\n",
        "    modelo = keras.Sequential([\n",
        "        keras.layers.Dense(64, activation='relu', input_shape=(caracteristicas.shape[1],)),\n",
        "        keras.layers.Dense(64, activation='relu'),\n",
        "        keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    modelo.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return modelo\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(caracteristicas, etiqueta, test_size=0.2, random_state=42)\n",
        "\n",
        "# Realizar Validación Cruzada k-fold con 5 pliegues\n",
        "kf = KFold(n_splits=5)\n",
        "scores = []\n",
        "\n",
        "for train_index, test_index in kf.split(X_train):\n",
        "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
        "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
        "\n",
        "    modelo = build_model()\n",
        "    modelo.fit(X_train_fold, y_train_fold, epochs=10, batch_size=32)\n",
        "    y_pred = modelo.predict(X_val_fold)\n",
        "    y_pred5 = np.where(y_pred > 0.5, 1, 0)\n",
        "    score = accuracy_score(y_val_fold, y_pred5)\n",
        "    scores.append(score)\n",
        "    print(f\"Precisión en pliegue {len(scores)}: {score}\")\n",
        "\n",
        "precisión_media = np.mean(scores)\n",
        "print(f\"Precisión media en Validación Cruzada k-fold (k=5): {precisión_media}\")"
      ],
      "metadata": {
        "id": "nCVuA6arDc7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#lo mismo que arriba pero calculando el rendimiento\n",
        "\n",
        "modelo = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    keras.layers.Dense(64, activation='relu'),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "modelo.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Entrenar el modelo\n",
        "modelo.fit(X_train, y_train, epochs=10, batch_size=32)\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "y_pred6 = modelo.predict(X_test)\n",
        "y_pred6 = np.where(y_pred6 > 0.5, 1, 0)\n",
        "\n",
        "# Evaluar el rendimiento del modelo\n",
        "print(\"Precisión:\", accuracy_score(y_test, y_pred6))\n",
        "print(classification_report(y_test, y_pred6, zero_division=0))"
      ],
      "metadata": {
        "id": "0HgraPliB5AD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validación simple de cada uno de los modelos."
      ],
      "metadata": {
        "id": "kj3to5PIST6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "precision= accuracy_score(y_test, y_pred)\n",
        "print(\"Precisión en Validación Simple:\", precision)\n",
        "precision1= accuracy_score(y_test, y_pred1)\n",
        "print(\"Precisión en Validación Simple:\", precision1)\n",
        "precision2= accuracy_score(y_test, y_pred2)\n",
        "print(\"Precisión en Validación Simple:\", precision2)\n",
        "precision3= accuracy_score(y_test, y_pred3)\n",
        "print(\"Precisión en Validación Simple:\", precision3)\n",
        "precision4= accuracy_score(y_test, y_pred4)\n",
        "print(\"Precisión en Validación Simple:\", precision4)\n",
        "precision5= accuracy_score(y_test, y_pred6)\n",
        "print(\"Precisión en Validación Simple:\", precision5)"
      ],
      "metadata": {
        "id": "9L6UBYPA6oAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testeando funcionalidades"
      ],
      "metadata": {
        "id": "597Hh2xZSCCI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "modelo = RandomForestClassifier(n_estimators=100)  # testeo con RandomForest las precisiones, etc\n",
        "modelo.fit(X_train, y_train)\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "y_pred9 = modelo.predict(X_test)\n",
        "\n",
        "# Calcular la matriz de confusión\n",
        "matriz_confusion = confusion_matrix(y_test, y_pred9)\n",
        "print(\"Matriz de Confusión:\")\n",
        "print(matriz_confusion)\n",
        "\n",
        "# Calcular la precisión (accuracy)\n",
        "precision9 = accuracy_score(y_test, y_pred9)\n",
        "print(\"Precisión:\", precision9)\n",
        "\n",
        "# Calcular la precisión (precision)\n",
        "precision9 = precision_score(y_test, y_pred9)\n",
        "print(\"Precisión (Precision):\", precision9)\n",
        "\n",
        "# Calcular el recall (sensibilidad)\n",
        "recall = recall_score(y_test, y_pred9)\n",
        "print(\"Recall (Sensibilidad):\", recall)\n",
        "\n",
        "# Calcular el F1-score\n",
        "f1 = f1_score(y_test, y_pred9)\n",
        "print(\"F1-score:\", f1)"
      ],
      "metadata": {
        "id": "MfvyL82yLkSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "modelo = DecisionTreeClassifier() #testeo k-fold con el arbolito\n",
        "\n",
        "# Realizar Validación Cruzada k-fold con 5 pliegues\n",
        "scores = cross_val_score(modelo, caracteristicas, etiqueta, cv=5, scoring='accuracy')\n",
        "\n",
        "# Imprimir los resultados de cada pliegue y la precisión media\n",
        "for i, score in enumerate(scores):\n",
        "    print(f\"Precisión en pliegue {i + 1}: {score}\")\n",
        "\n",
        "precisión_media = scores.mean()\n",
        "print(f\"Precisión media en Validación Cruzada k-fold (k=5): {precisión_media}\")"
      ],
      "metadata": {
        "id": "5FydkvAc61br"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hiper parámetros"
      ],
      "metadata": {
        "id": "-kpxe52oSrBw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Grid search"
      ],
      "metadata": {
        "id": "P_pdIJDrSwrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#grid search\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Define el modelo y los hiperparámetros a buscar\n",
        "modelo = RandomForestClassifier()\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "# Realiza la búsqueda en cuadrícula (Grid Search)\n",
        "grid_search = GridSearchCV(modelo, param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Obtiene los mejores hiperparámetros y el mejor modelo\n",
        "mejores_hiperparametros = grid_search.best_params_\n",
        "mejor_modelo = grid_search.best_estimator_\n",
        "\n",
        "print(\"Mejores hiperparámetros:\", mejores_hiperparametros)"
      ],
      "metadata": {
        "id": "9Or54o4fNBH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random search"
      ],
      "metadata": {
        "id": "Af2KWaecS2F6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#random search\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from scipy.stats import randint\n",
        "\n",
        "# Define el modelo y los hiperparámetros a buscar\n",
        "modelo = RandomForestClassifier()\n",
        "param_dist = {\n",
        "    'n_estimators': randint(50, 200),\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "# Realiza la búsqueda aleatoria (Random Search)\n",
        "random_search = RandomizedSearchCV(modelo, param_distributions=param_dist, n_iter=10, cv=5, scoring='accuracy')\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Obtiene los mejores hiperparámetros y el mejor modelo\n",
        "mejores_hiperparametros = random_search.best_params_\n",
        "mejor_modelo = random_search.best_estimator_\n",
        "\n",
        "print(\"Mejores hiperparámetros:\", mejores_hiperparametros)"
      ],
      "metadata": {
        "id": "sCmWaGsiQulD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ensamble de modelos: Votacion mayoritaria"
      ],
      "metadata": {
        "id": "uQR6q-QhS8_l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#votación mayoritaria\n",
        "\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Definir los modelos individuales\n",
        "modelo1 = RandomForestClassifier(n_estimators=100)\n",
        "modelo2 = GradientBoostingClassifier(n_estimators=100)\n",
        "modelo3 = LogisticRegression(solver='liblinear')\n",
        "\n",
        "# Crear el ensamblado por Votación Mayoritaria\n",
        "ensemble = VotingClassifier(estimators=[('rf', modelo1), ('gb', modelo2), ('lr', modelo3)], voting='hard')\n",
        "\n",
        "# Ajustar el ensamblado a los datos de entrenamiento\n",
        "ensemble.fit(X_train, y_train)\n",
        "\n",
        "# Realizar predicciones con el ensamblado\n",
        "y_pred = ensemble.predict(X_test)\n",
        "\n",
        "# Evaluar el rendimiento del ensamblado\n",
        "precisión = accuracy_score(y_test, y_pred)\n",
        "print(\"Precisión del ensamblado:\", precisión)"
      ],
      "metadata": {
        "id": "7x4sf2cjRq5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Desarrollo del programa:"
      ],
      "metadata": {
        "id": "S_Tc-4tRLZMq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Luego de haber aprendido de como trabajan cada uno de los modelos de machinelerning, creamos un diccionario con cada uno de ellos  y dividimos los datos en un conjunto de entrenamiento y prueba para entrenarlos.\n"
      ],
      "metadata": {
        "id": "zhiw88BZTNwg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#divido los datos en un conjunto de entrenamiento y de prueba y los entreno.\n",
        "\n",
        "models = {\n",
        "  'KNN': KNeighborsClassifier(),\n",
        "  'SVM': SVC(),\n",
        "  'Árbol de decisión': DecisionTreeClassifier(),\n",
        "  'Naive Bayes': GaussianNB(),\n",
        "  'Bosque aleatorio': RandomForestClassifier()\n",
        "}\n",
        "\n",
        "for name, model in models.items():\n",
        "  model.fit(X_train, y_train)\n",
        "  y_pred = model.predict(X_test)\n",
        "\n",
        "  print(f\"Model: {name}\")\n",
        "  print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
        "  print(f\"Recall: {recall_score(y_test, y_pred)}\")\n",
        "  print(f\"F1-score: {f1_score(y_test, y_pred)}\")\n",
        "  print(confusion_matrix(y_test, y_pred))\n",
        "  print(\"\\n\")"
      ],
      "metadata": {
        "id": "pE2waD68zhdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Luego creamos una función con 3 parametros en el cual uno de ellos es la cancion, el otro el nombre del artista y por ultimo el conjunto de modelos que vamos a estar utilizando.\n",
        "Dentro de esa función vamos a estar comprobando si el nombre de la cancion o del artista se encuentra en la \"base de datos\". En caso de encontrarse se realiza las predicciones en cada uno de los modelos y busca cual es la mas efectiva y si el rango es mayor a 0.5 va a devolver true o en caso de ser menor a 0.5 devuelve false y en el caso de no se encuentre va a devolver un string detallando que no se pudo encontrar. Si devuelve true quiere decir que hay posibilidad de que al usuario le gusta la cancion y si devuelve false de que no le guste."
      ],
      "metadata": {
        "id": "TIDBPcLAUbSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_song_preference(song_title, artist, models):\n",
        "  # Obtén las preferencias del usuario\n",
        "  user_preferences = hola.loc[(hola['song_title'].str.lower() == song_title.lower()) & (hola['artist'].str.lower() == artist.lower())]\n",
        "  user_preferences = user_preferences.head(1)\n",
        "  user_preferences = user_preferences.drop(['song_title', 'artist', 'target'], axis=1)\n",
        "  user_preferences.rename(columns={'Unnamed: 0': 'new_name'}, inplace=True)\n",
        "  user_preferences = user_preferences.drop('new_name', axis=1)\n",
        "\n",
        "  # Predice la preferencia del usuario para cada canción\n",
        "  song_preferences = {}\n",
        "  for name, model in models.items():\n",
        "      X_test_array = X_test.values\n",
        "      song_preferences[name] = model.predict(X_test_array)[0]\n",
        "\n",
        "  # Devuelve True si la canción le gustará al usuario, False en caso contrario\n",
        "  return song_preferences[max(song_preferences, key=song_preferences.get)] > 0.5"
      ],
      "metadata": {
        "id": "twrwrGo2_wHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_song_preference(song_title, artist, models):\n",
        "  # Obtén las preferencias del usuario\n",
        "  user_preferences = hola.loc[(hola['song_title'].str.lower() == song_title.lower()) & (hola['artist'].str.lower() == artist.lower())]\n",
        "  if not user_preferences.empty:\n",
        "    user_preferences = user_preferences.head(1)\n",
        "    user_preferences = user_preferences.drop(['song_title', 'artist', 'target'], axis=1)\n",
        "    user_preferences.rename(columns={'Unnamed: 0': 'new_name'}, inplace=True)\n",
        "    user_preferences = user_preferences.drop('new_name', axis=1)\n",
        "\n",
        "    # Predice la preferencia del usuario para cada canción\n",
        "    song_preferences = {}\n",
        "    for name, model in models.items():\n",
        "        X_test_array = X_test.values\n",
        "        song_preferences[name] = model.predict(X_test_array)[0]\n",
        "\n",
        "  # Devuelve True si la canción le gustará al usuario, False en caso contrario\n",
        "    return song_preferences[max(song_preferences, key=song_preferences.get)] > 0.5\n",
        "  else:\n",
        "    return \"La palabra no existe en el DataFrame.\""
      ],
      "metadata": {
        "id": "KND-4eWrJx2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def respuesta(hola): #verifica qué retorno la funcion del predict y le devuelve una respuesta al usuario o analista.\n",
        "  if solucion == True:\n",
        "    print(\"hay altas probabilidades de que le guste la canción\")\n",
        "  if solucion == \"La palabra no existe en el DataFrame.\":\n",
        "    print(\"No se ha encontrado la búsqueda\")\n",
        "  if solucion == False:\n",
        "    print(\"hay altas probabilidades de que no le gusta la canción\")"
      ],
      "metadata": {
        "id": "PhWT5HU4BBMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cancion=input(\"Nombre de canción: \")\n",
        "artista=input(\"Nombre del artista: \")"
      ],
      "metadata": {
        "id": "jQSVI7TBHTTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "solucion= predict_song_preference(cancion, artista, models)"
      ],
      "metadata": {
        "id": "SC4_7IN7Aje2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "respuesta(solucion)"
      ],
      "metadata": {
        "id": "y7fBWgEgB1X-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}